{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41fbb39a",
   "metadata": {},
   "source": [
    "A multi-layer perceptron approach to predicting coordinates of street view images. Must generate image embeddings before running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea390670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import dask.dataframe as dd\n",
    "import io\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba2137fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = pd.read_csv('coordinates.csv')\n",
    "image_feats = np.load('image_embeddings.npy')\n",
    "\n",
    "# will use later for normalizing coordinate inputs\n",
    "lat_min = coords[\"latitude\"].min()\n",
    "lat_max = coords[\"latitude\"].max()\n",
    "lon_min = coords[\"longitude\"].min()\n",
    "lon_max = coords[\"longitude\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5fc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to normalize/denormalize coordinates to [0,1]\n",
    "\n",
    "def normalize_coords(lat,lon):\n",
    "    # Normalize to [0, 1]\n",
    "    lat_norm = (lat - lat_min) / (lat_max - lat_min)\n",
    "    lon_norm = (lon - lon_min) / (lon_max - lon_min)\n",
    "\n",
    "    return lat_norm,lon_norm\n",
    "\n",
    "def denormalize_coords(lat_norm,lon_norm):\n",
    "    # If [0, 1] normalization\n",
    "    lat = lat_norm * (lat_max - lat_min) + lat_min\n",
    "    lon = lon_norm * (lon_max - lon_min) + lon_min\n",
    "\n",
    "    return lat,lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d003e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreetviewEmbeddingsDataset(Dataset):\n",
    "    '''\n",
    "    Dataset of streetview image StreetCLIP embeddings and corresponding coordinates\n",
    "    '''\n",
    "    def __init__(self, embeddings_path, coords):\n",
    "        self.embeddings_path = embeddings_path\n",
    "        self.coords = coords\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coords) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get target lat/lon\n",
    "        lat = torch.tensor(self.coords.iloc[idx][\"latitude\"], dtype=torch.float32)\n",
    "        lon = torch.tensor(self.coords.iloc[idx][\"longitude\"], dtype=torch.float32)\n",
    "\n",
    "        lat_norm,lon_norm = normalize_coords(lat,lon)\n",
    "\n",
    "        target = torch.stack([lat_norm, lon_norm])\n",
    "\n",
    "        embedding = self.embeddings_path[idx]\n",
    "        embedding_tensor = torch.from_numpy(embedding).float()\n",
    "\n",
    "        return embedding_tensor, target.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ac394fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataset\n",
    "\n",
    "dataset  = StreetviewEmbeddingsDataset(image_feats, coords)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e08a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# define MLP\n",
    "regressor = nn.Sequential(\n",
    "    nn.Linear(768, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 2),\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "# haversine loss function\n",
    "def haversine_loss(pred, true):\n",
    "    \"\"\"\n",
    "    pred and true should be (N, 2) tensors containing [latitude, longitude] in degrees\n",
    "    Returns: (N,) tensor of distances in kilometers\n",
    "    \"\"\"\n",
    "\n",
    "    # Denormalize the predictions\n",
    "    lat_pred = pred[:, 0] * (lat_max - lat_min) + lat_min\n",
    "    lon_pred = pred[:, 1] * (lon_max - lon_min) + lon_min\n",
    "\n",
    "    # Stack to form the denormalized predictions\n",
    "    denormalized_prediction = torch.stack([lat_pred, lon_pred], dim=1)\n",
    "\n",
    "    # Denormalize the ground truth\n",
    "    lat_true = true[:, 0] * (lat_max - lat_min) + lat_min\n",
    "    lon_true = true[:, 1] * (lon_max - lon_min) + lon_min\n",
    "\n",
    "    # Stack to form the ground truth\n",
    "    denormalized_truth = torch.stack([lat_true, lon_true], dim=1)\n",
    "\n",
    "\n",
    "    # calculate haversine distance\n",
    "    R = 6371.0  # Earth radius in km\n",
    "\n",
    "    pred_rad = torch.deg2rad(denormalized_prediction)\n",
    "    true_rad = torch.deg2rad(denormalized_truth)\n",
    "\n",
    "    dlat = pred_rad[:, 0] - true_rad[:, 0]\n",
    "    dlon = pred_rad[:, 1] - true_rad[:, 1]\n",
    "\n",
    "    a = torch.sin(dlat / 2) ** 2 + \\\n",
    "        torch.cos(true_rad[:, 0]) * torch.cos(pred_rad[:, 0]) * torch.sin(dlon / 2) ** 2\n",
    "\n",
    "    c = 2 * torch.atan2(torch.sqrt(a), torch.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "\n",
    "    return distance.mean()\n",
    "\n",
    "# define hyper parameters\n",
    "opt = torch.optim.Adam(regressor.parameters(), lr=1e-4)\n",
    "MSEloss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "312b1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, opt, loss_fn):\n",
    "    model.train()\n",
    "\n",
    "    opt.zero_grad()                    # Flush memory\n",
    "    batch_loss = loss_fn(model(x), y)  # Compute loss\n",
    "    batch_loss.backward()              # Compute gradients\n",
    "    opt.step()                         # Make a GD step\n",
    "\n",
    "    return batch_loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07caaf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch 1 of 10\n",
      "loss (km) 3572.0317\n",
      "Running epoch 2 of 10\n",
      "loss (km) 2081.3306\n",
      "Running epoch 3 of 10\n",
      "loss (km) 1813.5901\n",
      "Running epoch 4 of 10\n",
      "loss (km) 1651.7766\n",
      "Running epoch 5 of 10\n",
      "loss (km) 1534.0323\n",
      "Running epoch 6 of 10\n",
      "loss (km) 1458.6932\n",
      "Running epoch 7 of 10\n",
      "loss (km) 1398.6542\n",
      "Running epoch 8 of 10\n",
      "loss (km) 1346.727\n",
      "Running epoch 9 of 10\n",
      "loss (km) 1301.8749\n",
      "Running epoch 10 of 10\n",
      "loss (km) 1269.2413\n"
     ]
    }
   ],
   "source": [
    "# train MLP on image embeddings\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Running epoch {epoch + 1} of {n_epochs}\")\n",
    "\n",
    "    epoch_losses = []\n",
    "\n",
    "    # train\n",
    "    for batch in loader:\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, regressor, opt, haversine_loss) # using Haversine loss, can also use MSELoss\n",
    "        epoch_losses.append(batch_loss)\n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "\n",
    "    print('loss (km)',epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42bdcab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access HuggingFace streetview dataset to test KNN coordinate predictions\n",
    "# https://huggingface.co/datasets/stochastic/random_streetview_images_pano_v0.0.2\n",
    "\n",
    "test_images = dd.read_parquet(\"hf://datasets/stochastic/random_streetview_images_pano_v0.0.2/data/train-*-of-*.parquet\")\n",
    "row0 = test_images.head(1000)  # returns a Pandas DataFrame with the first 1000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d2c7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up StreetCLIP model to test new images with\n",
    "\n",
    "street_clip_model = CLIPModel.from_pretrained(\"geolocal/StreetCLIP\").to(device)\n",
    "street_clip_processor = CLIPProcessor.from_pretrained(\"geolocal/StreetCLIP\")\n",
    "\n",
    "def embed_image(byte_encoding):\n",
    "    '''\n",
    "    Generate an image embedding using StreetCLIP. Uses the images byte encoding\n",
    "\n",
    "    args: the image byte encoding\n",
    "    returns: a tensor of the image embedding\n",
    "    '''\n",
    "    # Load image\n",
    "    image = Image.open(io.BytesIO(byte_encoding)).convert('RGB')\n",
    "\n",
    "    # Process image\n",
    "    inputs = street_clip_processor(images=image, return_tensors=\"pt\", padding=True)\n",
    "    for k in inputs:\n",
    "        inputs[k] = inputs[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_feat = street_clip_model.get_image_features(**inputs)\n",
    "        image_feat = image_feat / image_feat.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return image_feat.squeeze(0)\n",
    "\n",
    "def haversine_distance_single_pair(true_lat, true_lon, pred_lat, pred_lon):\n",
    "    '''\n",
    "    Computes haversine distance between two points, use for testing one pair of points\n",
    "    \n",
    "    Parameters:\n",
    "    - true_lat, true_lon: float (degrees)\n",
    "    - pred_lat, pred_lon: float (degrees)\n",
    "    \n",
    "    Returns:\n",
    "    - distance in kilometers (float)\n",
    "    '''\n",
    "    R = 6371.0  # Earth radius in km\n",
    "\n",
    "    # Convert degrees to radians\n",
    "    true_lat_rad = np.deg2rad(true_lat)\n",
    "    true_lon_rad = np.deg2rad(true_lon)\n",
    "    pred_lat_rad = np.deg2rad(pred_lat)\n",
    "    pred_lon_rad = np.deg2rad(pred_lon)\n",
    "\n",
    "    # Differences\n",
    "    dlat = pred_lat_rad - true_lat_rad\n",
    "    dlon = pred_lon_rad - true_lon_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(true_lat_rad) * np.cos(pred_lat_rad) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    return R * c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8365089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.754967 127.98863\n",
      "26.6410333 128.0011105\n",
      "error (km) 568.6447390402274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_3cf0e2f74e0b1e0620c5122a4d463e53 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_3cf0e2f74e0b1e0620c5122a4d463e53&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_3cf0e2f74e0b1e0620c5122a4d463e53 = L.map(\n",
       "                &quot;map_3cf0e2f74e0b1e0620c5122a4d463e53&quot;,\n",
       "                {\n",
       "                    center: [26.6410333, 128.0011105],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    ...{\n",
       "  &quot;zoom&quot;: 10,\n",
       "  &quot;zoomControl&quot;: true,\n",
       "  &quot;preferCanvas&quot;: false,\n",
       "}\n",
       "\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_20c7babb3e19ebae2ff311ee71a22755 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 19,\n",
       "  &quot;maxNativeZoom&quot;: 19,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_20c7babb3e19ebae2ff311ee71a22755.addTo(map_3cf0e2f74e0b1e0620c5122a4d463e53);\n",
       "        \n",
       "    \n",
       "            var marker_fea8fa31c3020770e837e7233b31e6a7 = L.marker(\n",
       "                [26.6410333, 128.0011105],\n",
       "                {\n",
       "}\n",
       "            ).addTo(map_3cf0e2f74e0b1e0620c5122a4d463e53);\n",
       "        \n",
       "    \n",
       "            var icon_af8d1a90d698b3262101e8b57e2f03d5 = L.AwesomeMarkers.icon(\n",
       "                {\n",
       "  &quot;markerColor&quot;: &quot;blue&quot;,\n",
       "  &quot;iconColor&quot;: &quot;white&quot;,\n",
       "  &quot;icon&quot;: &quot;info-sign&quot;,\n",
       "  &quot;prefix&quot;: &quot;glyphicon&quot;,\n",
       "  &quot;extraClasses&quot;: &quot;fa-rotate-0&quot;,\n",
       "}\n",
       "            );\n",
       "        \n",
       "    \n",
       "        var popup_dd7fa21d070fa5ae60a6d8b5fc18c082 = L.popup({\n",
       "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
       "});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_a01603525d62ffd1e9fc1491d6acba80 = $(`&lt;div id=&quot;html_a01603525d62ffd1e9fc1491d6acba80&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Ground Truth&lt;/div&gt;`)[0];\n",
       "                popup_dd7fa21d070fa5ae60a6d8b5fc18c082.setContent(html_a01603525d62ffd1e9fc1491d6acba80);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_fea8fa31c3020770e837e7233b31e6a7.bindPopup(popup_dd7fa21d070fa5ae60a6d8b5fc18c082)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "                marker_fea8fa31c3020770e837e7233b31e6a7.setIcon(icon_af8d1a90d698b3262101e8b57e2f03d5);\n",
       "            \n",
       "    \n",
       "            var marker_7be5e0df09922a857de9f13341e2e74c = L.marker(\n",
       "                [31.754966735839844, 127.98863220214844],\n",
       "                {\n",
       "}\n",
       "            ).addTo(map_3cf0e2f74e0b1e0620c5122a4d463e53);\n",
       "        \n",
       "    \n",
       "            var icon_f57ccf1ee3cae0d0bcb9e55fad0146a3 = L.AwesomeMarkers.icon(\n",
       "                {\n",
       "  &quot;markerColor&quot;: &quot;red&quot;,\n",
       "  &quot;iconColor&quot;: &quot;white&quot;,\n",
       "  &quot;icon&quot;: &quot;info-sign&quot;,\n",
       "  &quot;prefix&quot;: &quot;glyphicon&quot;,\n",
       "  &quot;extraClasses&quot;: &quot;fa-rotate-0&quot;,\n",
       "}\n",
       "            );\n",
       "        \n",
       "    \n",
       "        var popup_e2feb5a4eb21f7a238d5439b36ae240f = L.popup({\n",
       "  &quot;maxWidth&quot;: &quot;100%&quot;,\n",
       "});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_ffb35c83e54ae6b7deb1911cb00ea4bb = $(`&lt;div id=&quot;html_ffb35c83e54ae6b7deb1911cb00ea4bb&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Prediction&lt;/div&gt;`)[0];\n",
       "                popup_e2feb5a4eb21f7a238d5439b36ae240f.setContent(html_ffb35c83e54ae6b7deb1911cb00ea4bb);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_7be5e0df09922a857de9f13341e2e74c.bindPopup(popup_e2feb5a4eb21f7a238d5439b36ae240f)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "                marker_7be5e0df09922a857de9f13341e2e74c.setIcon(icon_f57ccf1ee3cae0d0bcb9e55fad0146a3);\n",
       "            \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x31b6bdea0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = random.randint(0,999)\n",
    "\n",
    "# parse HuggingFace dataset\n",
    "true_lat = row0.iloc[rand]['latitude']\n",
    "true_lon = row0.iloc[rand]['longitude']\n",
    "img = row0.iloc[rand]['image'] # image is stored as a byte encoding\n",
    "address = row0.iloc[rand]['address']\n",
    "\n",
    "# generate image embedding\n",
    "embedding = embed_image(img['bytes'])\n",
    "\n",
    "# run regressor\n",
    "pred_coords = regressor(embedding)\n",
    "pred_lat,pred_lon = denormalize_coords(pred_coords[0],pred_coords[1])\n",
    "pred_lat = pred_lat.detach().numpy()\n",
    "pred_lon = pred_lon.detach().numpy()\n",
    "\n",
    "# create map\n",
    "m = folium.Map(location=(true_lat, true_lon))\n",
    "\n",
    "# add ground truth coordinates\n",
    "folium.Marker(\n",
    "    [true_lat, true_lon],\n",
    "    popup=\"Ground Truth\",\n",
    "    icon=folium.Icon(color='blue', icon='info-sign')\n",
    ").add_to(m)\n",
    "\n",
    "# add predicted coordinates\n",
    "folium.Marker(\n",
    "    [pred_lat, pred_lon],\n",
    "    popup=\"Prediction\",\n",
    "    icon=folium.Icon(color='red', icon='info-sign')\n",
    ").add_to(m)\n",
    "\n",
    "print(pred_lat,pred_lon)\n",
    "print(true_lat,true_lon)\n",
    "\n",
    "print('error (km)', haversine_distance_single_pair(float(true_lat), float(true_lon), pred_lat, pred_lon))\n",
    "\n",
    "# open image in a new window\n",
    "streetview = Image.open(io.BytesIO(img['bytes'])).convert('RGB')\n",
    "streetview.show()\n",
    "\n",
    "# display map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c4c65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred -34.958054 -67.02402\n",
      "true -47.7939291 -70.8289331\n",
      "error (km) 1461.680719968416\n",
      "--------------\n",
      "pred 53.58374 48.77768\n",
      "true 57.6012572 39.8765501\n",
      "error (km) 714.8384229762515\n",
      "--------------\n",
      "pred 16.717308 99.71855\n",
      "true 22.254943 113.913803\n",
      "error (km) 1609.2701250828693\n",
      "--------------\n",
      "pred 60.797478 30.135788\n",
      "true 63.0338146 23.9698275\n",
      "error (km) 407.17001522845896\n",
      "--------------\n",
      "pred 50.22065 9.857956\n",
      "true 50.8023156 3.3604827\n",
      "error (km) 463.8202353997078\n",
      "--------------\n",
      "pred 51.965256 7.345993\n",
      "true 56.3841469 23.7408113\n",
      "error (km) 1170.9377717620712\n",
      "--------------\n",
      "pred 35.37587 130.88387\n",
      "true 35.1078956 136.9538505\n",
      "error (km) 551.9660779699158\n",
      "--------------\n",
      "pred 9.706917 81.712265\n",
      "true 22.8233179 89.3411026\n",
      "error (km) 1669.305082009338\n",
      "--------------\n",
      "pred 37.917725 128.01488\n",
      "true 37.406581 127.0795934\n",
      "error (km) 100.04059332377943\n",
      "--------------\n",
      "pred 52.650703 18.921814\n",
      "true 61.0449791 24.9405562\n",
      "error (km) 1001.5854368312711\n",
      "--------------\n",
      "average error (km) 915.0614480552078\n"
     ]
    }
   ],
   "source": [
    "# test regressor on 10 random images from HuggingFace streetview dataset\n",
    "\n",
    "total_error = np.zeros(10)\n",
    "\n",
    "for i in range(10):\n",
    "    rand = random.randint(0,999)\n",
    "\n",
    "    # parse HuggingFace dataset\n",
    "    true_lat = row0.iloc[rand]['latitude']\n",
    "    true_lon = row0.iloc[rand]['longitude']\n",
    "    img = row0.iloc[rand]['image'] # image is stored as a byte encoding\n",
    "    address = row0.iloc[rand]['address']\n",
    "\n",
    "    # generate image embedding\n",
    "    embedding = embed_image(img['bytes'])\n",
    "\n",
    "    # run KNN \n",
    "    pred_coords = regressor(embedding)\n",
    "    pred_lat,pred_lon = denormalize_coords(pred_coords[0],pred_coords[1])\n",
    "    pred_lat = pred_lat.detach().numpy()\n",
    "    pred_lon = pred_lon.detach().numpy()\n",
    "\n",
    "    print('pred',pred_lat,pred_lon)\n",
    "    print('true',true_lat, true_lon)\n",
    "    error = haversine_distance_single_pair(float(true_lat), float(true_lon),pred_lat,pred_lon)\n",
    "    total_error[i] = error\n",
    "    print('error (km)',error)\n",
    "    print('--------------')\n",
    "\n",
    "print('average error (km)', np.mean(total_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
